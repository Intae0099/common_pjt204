## Ⅰ. 프로젝트 개요

### 1) 프로젝트 설명

**🏛️ LawAId - AI 기반 화상 법률 상담 플랫폼**
- **프로젝트명**: LawAId (Law + AI + Aid의 합성어)
- **개발 기간**: 2025.07.14 ~ 2025.08.17 (총 5주간)
- **팀 구성**: 6명 (AI 1명, 백엔드 2명, 프론트엔드 2명, 인프라 1명)
  - **본인 역할**: AI 백엔드 개발자 + DevOps 엔지니어 (단독 담당)

**📊 개발 배경 및 필요성**
- **사회적 문제**: 전체 국민의 56.2%가 법률 문제를 경험했지만 절반 이상이 상담을 받지 않음 (법률구조공단, 2023)
- **타겟 페인포인트**: 2030세대는 법률 서비스 수요가 있으나 진입장벽이 높다고 인식
- **솔루션 필요성**: 비대면 환경에서 화상 미팅, AI 법률 지원, 자동 문서 생성이 통합된 올인원 플랫폼
- **핵심 성과**: {{SSAFY 프로젝트 우수상/상장 정보 기입}}

### 2) 한 줄 요약

**2030 MZ세대의 법률 접근성 문제를 AI 기반 판례 검색과 실시간 화상 상담으로 해결하는 통합 디지털 플랫폼**

### 3) 목표(SMART)

**🎯 구체적 성과 목표**
- **S**pecific: RAG 시스템 기반 AI 법률 상담 서비스 구축
- **M**easurable: 판례 검색 정확도 Recall@10 55% 이상, 평균 응답시간 36초 이내
- **A**chievable: 45,000개 판례 + 5,502개 법령 데이터 기반 실용적 서비스
- **R**elevant: 2030세대 법률 접근성 향상에 직접적 기여
- **T**ime-bound: 2025.08.17까지 프로토타입 완성 및 성능 목표 달성

### 4) 주요 기능 3개

**🔍 AI 하이브리드 판례 검색**
- **목적**: 사용자 사건과 유사한 판례를 정확하게 찾아 법적 근거 제공
- **구현**: BM25 키워드 검색 + 벡터 유사도 검색 + Cross-Encoder 재정렬 3단계 시스템
- **성과**: 검색 정확도 Recall@10 55% 달성, 기존 PostgreSQL ILIKE 대비 대폭 향상

**📝 사건 구조화 및 문서 자동 생성**
- **목적**: 자유 형식의 사건 설명을 표준화된 법률 문서 형태로 변환
- **구현**: OpenAI GPT-4o + LangChain 기반 구조화 파이프라인
- **성과**: 상담 신청서 자동 생성으로 사용자 편의성 향상, 변호사 업무 효율성 증대

**💬 실시간 AI 법률 챗봇**
- **목적**: 24시간 즉시 법률 질의응답 서비스 제공
- **구현**: SSE(Server-Sent Events) 기반 실시간 스트리밍 + WebSocket 대화 관리
- **성과**: 실시간 응답으로 사용자 경험 향상, 초기 법률 상담 접근성 개선

### 5) 기술 스택(핵심 5)

**🛠️ 핵심 기술 스택 (본인 100% 담당)**
- **언어/프레임워크**: Python 3.10 + FastAPI (비동기 고성능 웹 서버)
- **데이터베이스**: PostgreSQL + pgvector (벡터 임베딩 저장 및 검색)
- **AI/LLM**: OpenAI GPT-4o + LangChain (RAG 체인 구성 및 프롬프트 엔지니어링)
- **배포/운영**: Docker + GitLab CI/CD (컨테이너 기반 자동 배포)
- **검색 엔진**: BM25 + Sentence-Transformers (하이브리드 검색 시스템)

**🔧 지원 라이브러리**
- **형태소 분석**: Kiwipiepy (한국어 법률 문서 특화 토큰화)
- **벡터 검색**: FAISS + pgvector (고속 유사도 검색)
- **모니터링**: Prometheus + Grafana (성능 지표 실시간 모니터링)

### 6) 시스템/데이터 개요

**🏗️ 시스템 아키텍처 흐름**
- **요청 처리**: Client → Nginx → FastAPI Router → Queue Manager → Service Layer → PostgreSQL+pgvector
- **서비스 계층**: CaseAnalysisService, SearchService, ChatService, StructuringService로 모듈화된 비동기 처리

**💾 데이터 파이프라인**
- **데이터 규모**: 법원 판례 45,000개 + 대한민국 법령 5,502개를 JSON 형태로 구조화
- **저장 방식**: pgvector에 768차원 벡터 임베딩 저장, case_id를 주키로 BM25 인덱스와 벡터 검색 병행
- **실시간 처리**: SQLite 기반 경량 큐 시스템으로 동시 요청 관리 및 리소스 최적화

### 7) 개인 역할/책임 범위

**🎯 담당 도메인 (AI 백엔드 시스템 전체)**
- **핵심 책임**: FastAPI 서버 아키텍처 설계, 하이브리드 검색 시스템 구현, LLM 기반 분석 서비스 개발
- **세부 모듈**: 판례 검색, 사건 분석, 법령 검증, 신뢰도 계산, 실시간 챗봇 등 AI 관련 모든 기능
- **의존성 관계**: 
  - **상위 의존**: 프론트엔드(Vue.js)와 백엔드(Spring Boot)에서 REST API 호출
  - **하위 의존**: PostgreSQL/pgvector DB 설계 및 OpenAI API 연동
- **최종 산출물**: 완전한 AI 법률 상담 API 서비스 (http://122.38.210.80:8997/docs)

---

## Ⅱ. 결과·증빙

### 7) 증빙 링크/스크린샷 2개

**🔗 실제 서비스 링크**
- **메인 레포지토리**: [GitLab - S13P11B204](https://lab.ssafy.com/s13-webmobile1-sub1/S13P11B204)
  - 전체 프로젝트 코드 베이스 (AI 백엔드는 `/ai` 디렉토리)
  - 개발 과정, 커밋 히스토리, 문서화 상태 확인 가능
  
- **AI 서비스 라이브 데모**: [FastAPI 자동 문서](http://122.38.210.80:8997/docs)
  - 실제 배포된 AI API 서버의 인터랙티브 문서
  - 판례 검색, 사건 분석, 챗봇 등 모든 API 엔드포인트 테스트 가능

**📷 주요 증빙 자료**
- {{스크린샷: RAG 성능 평가 결과 화면 (Recall@10 55% 달성 근거)}}
- {{스크린샷: FastAPI 자동 문서 및 실제 API 응답 결과}}

---

## Ⅲ. 개인 역할·성과

### B) 내 기여 Top3 (STAR 방식)

**🎯 기여 1: 검색 정확도 혁신적 개선**
- **S**ituation: PostgreSQL ILIKE 기반 검색의 정확도가 0%로 실용성 전무
- **T**ask: 45,000개 법원 판례에서 관련 사건을 정확하게 찾는 검색 시스템 구축 필요  
- **A**ction: BM25 키워드 검색 + Sentence-Transformers 벡터 검색 + Cross-Encoder 재정렬 하이브리드 시스템 개발
- **R**esult: **Recall@10 0% → 55% 향상**, MRR 0.000 → 0.250 달성으로 실용적 법률 AI 서비스 기반 마련

**⚡ 기여 2: 시스템 리소스 최적화**
- **S**ituation: 메모리 부족(OOM)으로 인한 시스템 크래시 빈발, 서비스 안정성 문제
- **T**ask: 제한된 서버 환경에서 대용량 AI 모델 안정적 운영 방안 필요
- **A**ction: Sentence-Transformer 모델 양자화(Quantization) 기법 적용 및 메모리 사용 패턴 최적화
- **R**esult: **메모리 사용량 2.5GB → 1.3GB (49.1% 절감)**, 99.8% 정확도 유지하며 시스템 안정성 확보

**🔍 기여 3: 객관적 신뢰도 시스템 구축**
- **S**ituation: LLM 기반 신뢰도 계산의 불투명성과 일관성 부족 문제
- **T**ask: 법률 상담에서 신뢰할 수 있는 객관적 신뢰도 지표 개발 필요
- **A**ction: 판례 유사도, 키워드 매칭률, 법령 정확도를 수치화한 다층 신뢰도 계산 알고리즘 설계
- **R**esult: **30-95% 범위 투명한 신뢰도 제공**, 과도한 확신 방지 및 사용자 신뢰성 향상

### C) 사용 기술(핵심 3) + 선택 근거

**🔍 BM25 + Kiwipiepy (하이브리드 검색 엔진)**
- **용도**: 한국어 법률 문서 특화 키워드 검색 및 형태소 분석
- **선택 근거**: PostgreSQL ILIKE 검색 대비 검색 정확도 대폭 향상, 법률 용어의 복합어 처리 최적화
- **성과 지표**: Recall@10 55% 달성, 45,000개 판례 인덱스 초기화 시간 수분→수초 단축

**🤖 OpenAI GPT-4o + LangChain (RAG 체인)**
- **용도**: 검색된 판례 기반 법률 분석 및 상담 내용 생성
- **선택 근거**: 최신 LLM 성능과 한국어 법률 도메인 이해도, LangChain을 통한 복잡한 프롬프트 체인 관리
- **성과 지표**: 평균 응답시간 36초 달성, 복잡한 분석 케이스도 안정적 처리

**💾 PostgreSQL + pgvector (벡터 데이터베이스)**
- **용도**: 5,502개 법령의 768차원 벡터 임베딩 저장 및 유사도 검색
- **선택 근거**: 관계형 DB의 안정성과 벡터 검색의 성능을 모두 제공, 실시간 법령 검증 지원
- **성과 지표**: 법령 조항 정확도 90% 이상, 실시간 벡터 검색으로 응답 속도 최적화

### E) 개인 성과 지표 (정량적 결과)

**📈 검색 시스템 성능 혁신**
- **Before → After**: Recall@10 0% → **55%**, MRR 0.000 → **0.250**
- **기술적 배경**: BM25 하이브리드 검색 시스템 도입으로 PostgreSQL ILIKE 방식 완전 대체
- **비즈니스 임팩트**: 실용적 법률 AI 서비스의 핵심 기반 기술 확립

**⚡ 시스템 리소스 최적화**
- **Before → After**: 메모리 사용량 2.5GB → **1.3GB (49.1% 절감)**
- **기술적 배경**: 모델 양자화(Quantization) 적용하여 99.8% 정확도 유지하며 메모리 효율성 극대화
- **비즈니스 임팩트**: 제한된 인프라 환경에서 안정적 서비스 제공 및 운영 비용 절감

### F) 모델/데이터 상세 (ML 백엔드 특화)

**📊 데이터셋 구성**
- **판례 데이터**: 대한민국 법원 판례 45,000개 (2000년~2023년), JSON 구조화 완료
- **법령 데이터**: 현행 대한민국 법령 5,502개, 조항별 세분화 및 벡터화
- **품질 관리**: 법무 전문가 검증 완료, 중복 제거 및 표준화 처리

**🎯 핵심 성능 지표**
- **주요 메트릭**: Recall@10 55.0% (상위 10개 검색 결과 내 정답 판례 포함률)
- **보조 지표**: Precision@1 15.0%, MRR 0.250, Citation Accuracy 15.0%
- **응답 속도**: 평균 36초 (복잡한 사건 분석), 단순 검색 2-5초

**🧪 실험 및 튜닝 과정**
- **베이스라인**: PostgreSQL ILIKE 텍스트 검색 (정확도 0%)
- **핵심 개선**: BM25 알고리즘 도입으로 **+55%p 정확도 향상**
- **추가 최적화**: Kiwipiepy 형태소 분석기로 한국어 법률 용어 토큰화 정확도 향상

### G) 주요 기술적 문제 해결 사례 (Incident 3건)

**🚨 문제 1: 메모리 부족(OOM) 및 시스템 크래시**
- **이슈**: 대용량 Sentence-Transformer 모델 로딩 시 메모리 부족으로 서버 다운
- **원인**: 768차원 임베딩 모델의 높은 메모리 요구사항과 동시 요청 처리
- **해결**: 모델 양자화(FP16) 적용 및 배치 처리 최적화
- **검증**: 메모리 사용량 49.1% 절감 확인, Grafana 모니터링으로 안정성 검증

**🔍 문제 2: 검색 정확도 제로 상태**
- **이슈**: PostgreSQL ILIKE 기반 검색으로 관련 판례를 전혀 찾지 못함 (Recall@10 0%)
- **원인**: 단순 텍스트 매칭의 한계와 법률 용어의 복합어 처리 부족
- **해결**: BM25 + Kiwipiepy 형태소 분석기 기반 하이브리드 검색 시스템 구축
- **검증**: Recall@10 55% 달성, 평가 데이터셋을 통한 정량적 성능 측정

**⚖️ 문제 3: 신뢰도 계산 불투명성**
- **이슈**: LLM에만 의존한 신뢰도 계산으로 일관성 부족 및 과도한 확신 문제
- **원인**: GPT 모델의 블랙박스 특성과 도메인별 신뢰도 기준 부재
- **해결**: 판례 유사도, 키워드 매칭률, 법령 정확도 기반 다층 객관적 신뢰도 시스템 개발
- **검증**: 30-95% 범위 투명성 확보, 신뢰도 계산 로직 문서화 완료

### H) 개인 회고 및 성장 (KPT 분석)

**✅ Keep (지속할 것)**
- **효율적 배포 시스템**: GitLab CI/CD와 Mattermost 연동으로 15-20분 내 자동 배포 완료
- **체계적 문서화**: API 자동 문서화(FastAPI) + 아키텍처 문서로 팀 협업 효율성 극대화
- **지속적 성능 모니터링**: Prometheus + Grafana 기반 실시간 메트릭 수집 및 이슈 조기 발견

**⚠️ Problem (개선 필요)**
- **상위 순위 검색 정확도**: Recall@1 15%로 최상위 결과 정확도 개선 필요
- **응답 시간 최적화**: 복잡한 분석 36초를 20초 이내로 단축 요구
- **Cross-Encoder 성능**: 최종 재정렬 단계에서 더 정교한 순위 조정 알고리즘 필요

**🚀 Try (새로운 시도)**
- **세션 관리 고도화**: 현재 인메모리 방식을 Redis 외부 저장소로 확장하여 대화 일관성 향상
- **고가용성(HA) 구성**: 로드밸런서 + 다중 서버 구성으로 무중단 서비스 아키텍처 구현
- **도메인 특화 모델**: 법률 도메인 특화 임베딩 모델 파인튜닝으로 검색 정확도 90% 목표

---

# 📊 프로젝트 하이라이트 요약

## 🏆 LawAId: AI 기반 화상 법률 상담 플랫폼

### ⭐ 핵심 성과 한눈에 보기
```
🎯 검색 정확도 혁신      : Recall@10 0% → 55% (BM25 하이브리드 검색)
⚡ 시스템 최적화         : 메모리 사용량 49.1% 절감 (2.5GB → 1.3GB)  
📊 데이터 처리 규모      : 판례 45,000개 + 법령 5,502개 벡터화
🕐 개발 완주            : 5주 스프린트 (AI 백엔드 시스템 100% 단독 개발)
🚀 실제 서비스 배포      : http://122.38.210.80:8997/docs (라이브 운영)
```

### 🎨 기술적 차별화 포인트
1. **🔍 3단계 하이브리드 RAG**: BM25 키워드 → 벡터 유사도 → Cross-Encoder 재정렬
2. **⚖️ 객관적 신뢰도 시스템**: 30-95% 범위 투명한 신뢰도 (판례 유사도 + 키워드 매칭률 + 법령 정확도)
3. **🏗️ 모듈화된 아키텍처**: FastAPI 기반 비동기 서비스 레이어 (Analysis/Search/Chat/Structuring)
4. **🔄 완전 자동화 CI/CD**: GitLab → Docker → 배포까지 15-20분 무중단 파이프라인

### 📈 개인 성장 스토리
```
시작점 (2025.07.14)     전환점 (2025.08.05)        현재 (2025.08.17)
─────────────────       ─────────────────         ─────────────────
❌ 검색 정확도 0%        🔍 BM25 시스템 도입        ✅ Recall@10 55%
❌ 메모리 부족 OOM       ⚡ 모델 양자화 적용        ✅ 메모리 49% 절감  
❌ LLM 신뢰도 불투명     🎯 객관적 지표 개발        ✅ 30-95% 투명성
```

---

## 📋 성과 근거 및 검증 자료

### 🔍 주요 수치의 출처 및 근거
- **성능 지표**: `ai/docs/CONTRIBUTIONS.md` (L42, L60-70) - RAG 성능 개선 요약표
- **메모리 최적화**: `ai/docs/retrospective.md` (L19, L37-38) - 시스템 최적화 섹션
- **데이터 규모**: `ai/README.md` (L25), `ai/docs/ARCHITECTURE.md` (L25) - 데이터셋 설명
- **응답 시간**: `ai/docs/retrospective.md` (L20) - API 안정성 메트릭
- **기술 스택**: `ai/requirements.txt`, `ai/environment.yml` - 실제 의존성 목록

### 🧪 평가 시스템 검증
- **평가 도구**: `ai/evaluation/evaluate_rag.py` - 자동화된 성능 측정 스크립트
- **메트릭 계산**: `ai/evaluation/utils/metrics.py` - Recall, Precision, MRR 계산 로직
- **성능 모니터링**: `ai/docs/OPERATIONS.md` - Prometheus/Grafana 기반 실시간 모니터링

### 📷 시각적 증빙 자료 (준비 필요)
- {{스크린샷: RAG 평가 결과 대시보드 (Recall@10 55% 표시)}}
- {{스크린샷: Grafana 메모리 사용량 그래프 (49.1% 절감 확인)}}
- {{스크린샷: FastAPI 자동 생성 문서 (실제 API 엔드포인트)}}
- {{스크린샷: GitLab CI/CD 파이프라인 (15-20분 배포 시간 확인)}}

---

## 💼 포트폴리오 활용 가이드

### ✅ 이력서 요약 버전 (3줄)
```
AI 기반 법률 상담 플랫폼의 RAG 시스템을 설계하여 판례 검색 정확도 55% 달성
BM25 하이브리드 검색과 모델 양자화로 메모리 사용량 49.1% 절감하며 시스템 안정성 확보  
5주간 AI 백엔드 시스템 전체를 단독 개발하여 실제 서비스 배포 및 운영 중
```

### 🎯 면접 예상 질문 대응
1. **"검색 정확도 55%가 어떻게 측정되었나요?"**
   → `ai/evaluation/` 디렉토리의 자동 평가 시스템과 Recall@10 메트릭 설명

2. **"메모리 최적화는 구체적으로 어떻게 했나요?"** 
   → Sentence-Transformer 모델 양자화(FP16) 기법과 배치 처리 최적화 설명

3. **"실제 서비스에서 사용할 수 있는 수준인가요?"**
   → 라이브 데모 링크(http://122.38.210.80:8997/docs) 제공 및 36초 평균 응답시간 근거

---

*본 문서는 실제 개발 과정과 성과를 바탕으로 작성되었으며, 모든 수치는 프로젝트 내 문서와 코드로 검증 가능합니다.*