# ALaw 프로젝트 회고

## 1. 프로젝트 한 줄 요약

AI 기반 RAG 시스템을 구축하여 판례 검색의 정확도를 55%까지 향상시키고, BM25 알고리즘 도입으로 시스템 성능을 49.1% 최적화한 법률 AI 백엔드를 개발했다.

## 2. 프로젝트 개요

• **프로젝트명**: ALaw (AI 기반 화상 법률 상담 플랫폼)
• **기간**: 2025.07.14 ~ 2025.08.17
• **팀 구성**: 6명 (AI 1명, 백엔드 2명, 프론트엔드 2명, 인프라 1명)
• **기술 스택**: FastAPI, PostgreSQL, OpenAI GPT-4o, BM25, LangChain, Docker
• **목표**: AI 기반 판례 검색과 법률 분석을 통해 사용자의 법률 상담 접근성을 향상시키는 서비스 개발

## 3. 주요 성과와 하이라이트

### 정량적 성과
• **검색 성능**: BM25 도입으로 Recall@10 55% 달성 (기존 ILIKE 검색 대비 유의미한 향상)
• **시스템 최적화**: 메모리 사용량 2.5GB → 1.3GB (49.1% 절감)
• **API 안정성**: 성공률 100% 달성, 복잡한 분석 36초, 단순 검색 2-5초

### 정성적 성과
• **하이브리드 RAG 시스템**: BM25 + 벡터 검색 + Cross-Encoder 3단계 필터링 구현
• **객관적 신뢰도 시스템**: LLM 의존적 신뢰도를 판례 유사도 기반 객관적 지표로 대체
• **45,000개 판례 + 5,502개 법령 DB**: 포괄적인 법률 데이터베이스 구축
• **실시간 스트리밍 챗봇**: SSE 기반 GPT-4o 실시간 법률 상담 서비스

## 4. 도전 과제와 해결 과정

### 도전 1: 검색 정확도 향상
**문제**: 기존 PostgreSQL ILIKE 검색의 낮은 정확도와 느린 응답 속도
**해결**: BM25 알고리즘 도입으로 키워드 기반 정확도 향상 + 피클 캐싱으로 초기화 시간 단축
**결과**: Recall@10 55% 달성, 검색 응답 시간 대폭 개선

### 도전 2: 시스템 리소스 최적화
**문제**: 메모리 부족으로 인한 시스템 성능 한계
**해결**: 모델 양자화(Quantization) 기법 적용으로 메모리 사용량 최적화
**결과**: 메모리 사용량 49.1% 절감, 시스템 안정성 향상

### 도전 3: 신뢰도 계산 개선
**문제**: LLM에 의존적인 신뢰도 계산으로 불투명성 문제
**해결**: 판례 유사도, 키워드 매칭률, 법령 정확도 등 정량적 지표를 수치화하여 객관적 신뢰도 시스템 구축
**결과**: 과도한 확신 방지 및 신뢰도 투명성 확보

## 5. Lessons Learned

### 기술적 배움
• **BM25 vs 벡터 검색**: 법률 도메인에서 키워드 기반 희소 검색과 의미 기반 밀집 검색의 상호 보완성
• **FastAPI + asyncio**: 비동기 프로그래밍으로 높은 동시성 달성하는 방법
• **LangChain 체인 설계**: 복잡한 AI 워크플로우를 모듈화하고 관리하는 패턴
• **Cross-Encoder 활용**: 검색 결과 재정렬을 통한 최종 정확도 향상 기법

### 협업 배움
• **의존성 주입 패턴**: FastAPI 컨테이너를 활용한 테스트 가능하고 유지보수 가능한 아키텍처 설계
• **GitLab CI/CD**: 자동화된 배포 파이프라인으로 개발 효율성 향상
• **API 문서화**: FastAPI 자동 문서화로 프론트엔드팀과의 원활한 협업 경험

### 개인 성장
• **성능 최적화 마인드**: 단순한 기능 구현을 넘어 시스템 전체의 효율성을 고려하는 시각 습득
• **데이터 기반 의사결정**: 주관적 판단 대신 메트릭과 평가 결과를 바탕으로 한 개선 방향 설정

## 6. 다음에 시도하고 싶은 것

• **검색 정확도 90% 달성**: Cross-Encoder 강화와 법률 도메인 특화 임베딩 모델 파인튜닝
• **고가용성(HA) 구성**: Redis 세션 관리 + 로드밸런서를 통한 무중단 서비스 구축
• **실시간 응답 시간 2초 이내**: 현재 36초 분석 시간을 캐싱과 인덱스 최적화로 단축
• **클라우드 네이티브 아키텍처**: Kubernetes 기반 자동 스케일링 시스템 도입

## 7. 마무리 한 줄

이번 프로젝트는 AI와 백엔드 기술을 결합하여 실제 사회 문제를 해결하는 서비스를 만들면서, 기술적 최적화와 사용자 가치 창출 모두를 경험할 수 있었던 소중한 기회였다. 앞으로는 더 정확하고 빠른 AI 서비스로 법률 접근성 향상에 기여하겠다.

---

## 프로젝트 하이라이트

**BM25 검색 시스템 도입의 임팩트**
PostgreSQL ILIKE 검색의 한계를 극복하기 위해 BM25 알고리즘을 도입했을 때, 단순히 성능 향상만 이룬 것이 아니라 전체 시스템 아키텍처를 재설계하는 계기가 되었다. Kiwipiepy 한국어 형태소 분석기와 피클 캐싱 시스템을 결합하여 45,000개 판례 인덱스의 초기화 시간을 수분에서 수초로 단축시킨 순간, RAG 시스템의 진정한 잠재력을 실감했다.

## 기술적 성장 스토리

**시작**: AI와 백엔드 모두 초보 수준에서 법률 도메인의 복잡성에 압도당했다
**중간**: LangChain, 벡터 DB, 하이브리드 검색을 하나씩 학습하며 45,000개 판례로 실험을 반복했다
**결과**: RAG 파이프라인 전체를 설계하고 최적화하여 실제 법률 상담에 활용 가능한 수준의 AI 시스템을 완성했다

## 한 줄 슬로건

"정확성과 효율성, 두 마리 토끼를 모두 잡는 AI 시스템"