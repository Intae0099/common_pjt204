# âš™ï¸ ê°œë°œ ê°€ì´ë“œ

ALaw AI-Backend ê°œë°œì„ ìœ„í•œ ê°€ì´ë“œì…ë‹ˆë‹¤.

## ğŸ“‹ ëª©ì°¨

- [ê°œë°œ í™˜ê²½ ì„¤ì •](#ê°œë°œ-í™˜ê²½-ì„¤ì •)
- [í”„ë¡œì íŠ¸ êµ¬ì¡°](#í”„ë¡œì íŠ¸-êµ¬ì¡°)
- [ê°œë°œ ì›Œí¬í”Œë¡œìš°](#ê°œë°œ-ì›Œí¬í”Œë¡œìš°)
- [ì½”ë”© ì»¨ë²¤ì…˜](#ì½”ë”©-ì»¨ë²¤ì…˜)
- [ë””ë²„ê¹…](#ë””ë²„ê¹…)
- [ì„±ëŠ¥ ìµœì í™”](#ì„±ëŠ¥-ìµœì í™”)

---

## ê°œë°œ í™˜ê²½ ì„¤ì •

### 1. ì‚¬ì „ ìš”êµ¬ì‚¬í•­

```bash
# Python 3.10+ ì„¤ì¹˜ í™•ì¸
python --version

# Git ì„¤ì¹˜ í™•ì¸
git --version

# Docker ì„¤ì¹˜ í™•ì¸ (ì„ íƒì‚¬í•­)
docker --version
```

### 2. ê°œë°œ í™˜ê²½ êµ¬ì„±

```bash
# ë¦¬í¬ì§€í† ë¦¬ í´ë¡ 
git clone https://github.com/your-repo/ALaw-AI-Backend.git
cd ALaw-AI-Backend

# ê°€ìƒí™˜ê²½ ìƒì„± ë° í™œì„±í™”
python -m venv venv
source venv/bin/activate  # macOS/Linux
# venv\Scripts\activate   # Windows

# ê°œë°œ ì˜ì¡´ì„± ì„¤ì¹˜
pip install -r requirements-dev.txt

# pre-commit í›… ì„¤ì¹˜
pre-commit install
```

### 3. í™˜ê²½ ë³€ìˆ˜ ì„¤ì •

```bash
# ê°œë°œìš© í™˜ê²½ íŒŒì¼ ìƒì„±
cp config/.env.example config/.env.dev

# í™˜ê²½ ë³€ìˆ˜ í¸ì§‘
nano config/.env.dev
```

**config/.env.dev ì˜ˆì‹œ**:
```env
# í™˜ê²½
ENVIRONMENT=development
DEBUG=true

# ë°ì´í„°ë² ì´ìŠ¤
DATABASE_URL=postgresql://postgres:password@localhost:5432/alaw_ai_dev

# AI ëª¨ë¸
OPENAI_API_KEY=your-api-key-here
EMBEDDING_MODEL=snunlp/KR-SBERT-V40K-klueNLI-augSTS

# ë¡œê¹…
LOG_LEVEL=DEBUG
LOG_FILE=logs/dev.log

# í ì‹œìŠ¤í…œ
QUEUE_DB_PATH=data/queue_dev.db
```

### 4. ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì •

```bash
# PostgreSQL ê°œë°œ DB ìƒì„±
createdb alaw_ai_dev

# pgvector í™•ì¥ ì„¤ì¹˜
psql alaw_ai_dev -c "CREATE EXTENSION IF NOT EXISTS vector;"

# ìŠ¤í‚¤ë§ˆ ì´ˆê¸°í™”
psql alaw_ai_dev -f db/init_schema.sql
```

---

## í”„ë¡œì íŠ¸ êµ¬ì¡°

```
ALaw-AI-Backend/
â”œâ”€â”€ app/                    # FastAPI ì• í”Œë¦¬ì¼€ì´ì…˜
â”‚   â”œâ”€â”€ api/               # API ë¼ìš°í„° ë° ì—”ë“œí¬ì¸íŠ¸
â”‚   â”‚   â”œâ”€â”€ routers/      # ê° ê¸°ëŠ¥ë³„ ë¼ìš°í„°
â”‚   â”‚   â”œâ”€â”€ schemas/      # Pydantic ëª¨ë¸
â”‚   â”‚   â””â”€â”€ handlers.py   # ì˜ˆì™¸ ì²˜ë¦¬ê¸°
â”‚   â””â”€â”€ main.py           # ì• í”Œë¦¬ì¼€ì´ì…˜ ì§„ì…ì 
â”œâ”€â”€ services/              # ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ ì„œë¹„ìŠ¤
â”‚   â”œâ”€â”€ search_service.py     # ê²€ìƒ‰ ê´€ë ¨
â”‚   â”œâ”€â”€ case_analysis_service.py  # ì¼€ì´ìŠ¤ ë¶„ì„
â”‚   â”œâ”€â”€ chat_service.py       # ì±—ë´‡
â”‚   â””â”€â”€ ...
â”œâ”€â”€ utils/                 # ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
â”‚   â”œâ”€â”€ logger.py         # ë¡œê¹… ì„¤ì •
â”‚   â”œâ”€â”€ exceptions.py     # ì»¤ìŠ¤í…€ ì˜ˆì™¸
â”‚   â””â”€â”€ confidence_calculator.py
â”œâ”€â”€ config/                # ì„¤ì • íŒŒì¼
â”‚   â”œâ”€â”€ settings.py       # ì„¤ì • í´ë˜ìŠ¤
â”‚   â””â”€â”€ .env.example     # í™˜ê²½ ë³€ìˆ˜ í…œí”Œë¦¿
â”œâ”€â”€ db/                    # ë°ì´í„°ë² ì´ìŠ¤ ê´€ë ¨
â”‚   â”œâ”€â”€ database.py       # DB ì—°ê²° ì„¤ì •
â”‚   â””â”€â”€ *.sql            # SQL ìŠ¤í¬ë¦½íŠ¸
â”œâ”€â”€ llm/                   # LLM ê´€ë ¨ ëª¨ë“ˆ
â”‚   â”œâ”€â”€ models/          # ëª¨ë¸ ë˜í¼
â”‚   â””â”€â”€ clients/         # LLM í´ë¼ì´ì–¸íŠ¸
â”œâ”€â”€ tests/                 # í…ŒìŠ¤íŠ¸ ì½”ë“œ
â”‚   â”œâ”€â”€ conftest.py      # í…ŒìŠ¤íŠ¸ ì„¤ì •
â”‚   â”œâ”€â”€ services/        # ì„œë¹„ìŠ¤ í…ŒìŠ¤íŠ¸
â”‚   â””â”€â”€ api/             # API í…ŒìŠ¤íŠ¸
â”œâ”€â”€ docs/                  # ë¬¸ì„œ
â”œâ”€â”€ docker/                # Docker ì„¤ì •
â””â”€â”€ requirements*.txt      # ì˜ì¡´ì„± ëª©ë¡
```

### ì£¼ìš” ëª¨ë“ˆ ì„¤ëª…

#### 1. Services Layer
```python
# services/base_service.py
class BaseService:
    """ëª¨ë“  ì„œë¹„ìŠ¤ì˜ ê¸°ë³¸ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.logger = get_logger(self.__class__.__name__)
    
    @handle_service_exceptions("ì„œë¹„ìŠ¤ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
    async def process(self, *args, **kwargs):
        # ê³µí†µ ì²˜ë¦¬ ë¡œì§
        pass
```

#### 2. API Layer
```python
# app/api/routers/example.py
from fastapi import APIRouter, Depends
from app.api.schemas.example import ExampleRequest, ExampleResponse

router = APIRouter(prefix="/api/example", tags=["example"])

@router.post("/", response_model=ExampleResponse)
async def process_example(
    request: ExampleRequest,
    service: ExampleService = Depends(get_example_service)
):
    result = await service.process(request)
    return ExampleResponse(data=result)
```

#### 3. Configuration
```python
# config/settings.py
from pydantic_settings import BaseSettings

class Settings(BaseSettings):
    environment: str = "development"
    debug: bool = False
    database_url: str
    openai_api_key: str
    
    class Config:
        env_file = "config/.env"
```

---

## ê°œë°œ ì›Œí¬í”Œë¡œìš°

### 1. ê¸°ëŠ¥ ê°œë°œ í”„ë¡œì„¸ìŠ¤

```bash
# 1. ìƒˆ ë¸Œëœì¹˜ ìƒì„±
git checkout -b feature/new-feature

# 2. ê°œë°œ ì§„í–‰
# - ì½”ë“œ ì‘ì„±
# - í…ŒìŠ¤íŠ¸ ì‘ì„±
# - ë¬¸ì„œ ì—…ë°ì´íŠ¸

# 3. í…ŒìŠ¤íŠ¸ ì‹¤í–‰
pytest tests/ -v

# 4. ì½”ë“œ í’ˆì§ˆ ê²€ì‚¬
black .
isort .
flake8 .
mypy .

# 5. ì»¤ë°‹ ë° í‘¸ì‹œ
git add .
git commit -m "feat: add new feature"
git push origin feature/new-feature

# 6. Pull Request ìƒì„±
```

### 2. í…ŒìŠ¤íŠ¸ ì£¼ë„ ê°œë°œ (TDD)

```python
# 1. ì‹¤íŒ¨í•˜ëŠ” í…ŒìŠ¤íŠ¸ ì‘ì„±
def test_new_feature():
    service = NewService()
    result = service.new_method("input")
    assert result == "expected_output"

# 2. ìµœì†Œí•œì˜ êµ¬í˜„
class NewService:
    def new_method(self, input_data):
        return "expected_output"

# 3. ë¦¬íŒ©í† ë§
class NewService:
    def new_method(self, input_data):
        # ì‹¤ì œ ë¡œì§ êµ¬í˜„
        processed = self._process(input_data)
        return self._format_output(processed)
```

### 3. API ë¨¼ì € ì„¤ê³„ (API-First)

```python
# 1. ìŠ¤í‚¤ë§ˆ ì •ì˜
class AnalysisRequest(BaseModel):
    case_text: str = Field(..., min_length=10, max_length=10000)
    options: Dict[str, Any] = Field(default_factory=dict)

class AnalysisResponse(BaseModel):
    success: bool
    data: AnalysisResult
    confidence: float = Field(..., ge=0.0, le=1.0)

# 2. API ì—”ë“œí¬ì¸íŠ¸ ì •ì˜
@router.post("/analyze", response_model=AnalysisResponse)
async def analyze_case(request: AnalysisRequest):
    # TODO: êµ¬í˜„
    pass

# 3. ì„œë¹„ìŠ¤ ë¡œì§ êµ¬í˜„
class AnalysisService:
    async def analyze(self, case_text: str, options: dict) -> AnalysisResult:
        # êµ¬í˜„
        pass
```

---

## ì½”ë”© ì»¨ë²¤ì…˜

### 1. Python ìŠ¤íƒ€ì¼ ê°€ì´ë“œ

**Black + isort ì„¤ì •** (pyproject.toml):
```toml
[tool.black]
line-length = 88
target-version = ['py310']

[tool.isort]
profile = "black"
multi_line_output = 3
line_length = 88
```

### 2. ë„¤ì´ë° ì»¨ë²¤ì…˜

```python
# í´ë˜ìŠ¤: PascalCase
class SearchService:
    pass

# í•¨ìˆ˜/ë³€ìˆ˜: snake_case
def analyze_case():
    user_input = "example"

# ìƒìˆ˜: UPPER_SNAKE_CASE
MAX_RETRY_COUNT = 3

# Private ë©¤ë²„: ì•ì— ì–¸ë”ìŠ¤ì½”ì–´
class Service:
    def __init__(self):
        self._private_var = None
    
    def _private_method(self):
        pass
```

### 3. ë¬¸ì„œí™”

```python
class SearchService:
    """ë²•ë¥  íŒë¡€ ê²€ìƒ‰ ì„œë¹„ìŠ¤
    
    í‚¤ì›Œë“œ ê²€ìƒ‰ê³¼ ë²¡í„° ê²€ìƒ‰ì„ ê²°í•©í•œ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ì„ ì œê³µí•©ë‹ˆë‹¤.
    """
    
    async def vector_search(self, query: str, size: int = 10) -> tuple[list[dict], int]:
        """ë²¡í„° ê¸°ë°˜ ìœ ì‚¬ì„± ê²€ìƒ‰
        
        Args:
            query: ê²€ìƒ‰ ì¿¼ë¦¬ ë¬¸ìì—´
            size: ë°˜í™˜í•  ê²°ê³¼ ìˆ˜ (ê¸°ë³¸ê°’: 10)
            
        Returns:
            tuple: (ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸, ì „ì²´ ê²°ê³¼ ìˆ˜)
            
        Raises:
            SearchError: ê²€ìƒ‰ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ ì‹œ
            ValidationError: ì…ë ¥ ë°ì´í„° ê²€ì¦ ì‹¤íŒ¨ ì‹œ
            
        Example:
            >>> service = SearchService()
            >>> results, total = await service.vector_search("ê³„ì•½ ìœ„ë°˜", 5)
            >>> print(f"ì´ {total}ê°œ ì¤‘ {len(results)}ê°œ ê²°ê³¼")
        """
        pass
```

### 4. ì—ëŸ¬ ì²˜ë¦¬

```python
# ì»¤ìŠ¤í…€ ì˜ˆì™¸ ì‚¬ìš©
from utils.exceptions import SearchError, ValidationError

class SearchService:
    @handle_service_exceptions("ê²€ìƒ‰ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
    async def search(self, query: str) -> list[dict]:
        try:
            # ê²€ìƒ‰ ë¡œì§
            results = await self._perform_search(query)
            return results
        except DatabaseError as e:
            # DB ì˜¤ë¥˜ëŠ” SearchErrorë¡œ ë³€í™˜
            raise SearchError(f"ê²€ìƒ‰ ì¤‘ ë°ì´í„°ë² ì´ìŠ¤ ì˜¤ë¥˜: {e}") from e
        except Exception as e:
            # ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ëŠ” ë°ì½”ë ˆì´í„°ê°€ ì²˜ë¦¬
            raise
```

---

## ë””ë²„ê¹…

### 1. ë¡œê¹… ì„¤ì •

```python
# utils/logger.py ì‚¬ìš©
from utils.logger import get_logger

logger = get_logger(__name__)

class SearchService:
    async def search(self, query: str):
        logger.info(f"ê²€ìƒ‰ ì‹œì‘: query='{query}'")
        
        try:
            results = await self._search_impl(query)
            logger.info(f"ê²€ìƒ‰ ì™„ë£Œ: {len(results)}ê°œ ê²°ê³¼")
            return results
        except Exception as e:
            logger.error(f"ê²€ìƒ‰ ì‹¤íŒ¨: {e}", exc_info=True)
            raise
```

### 2. ë””ë²„ê¹… ë„êµ¬

```python
# 1. pdb ì‚¬ìš©
import pdb; pdb.set_trace()

# 2. breakpoint() ì‚¬ìš© (Python 3.7+)
breakpoint()

# 3. ë¡œê·¸ ê¸°ë°˜ ë””ë²„ê¹…
logger.debug(f"ë³€ìˆ˜ ìƒíƒœ: {variable}")
logger.debug(f"í•¨ìˆ˜ í˜¸ì¶œ: {func.__name__}({args}, {kwargs})")
```

### 3. í…ŒìŠ¤íŠ¸ ë””ë²„ê¹…

```bash
# íŠ¹ì • í…ŒìŠ¤íŠ¸ë§Œ ì‹¤í–‰
pytest tests/test_search.py::test_vector_search -v

# ë””ë²„ê¹… ëª¨ë“œë¡œ ì‹¤í–‰
pytest --pdb tests/test_search.py

# ì‹¤íŒ¨í•œ í…ŒìŠ¤íŠ¸ë§Œ ì¬ì‹¤í–‰
pytest --lf

# ì»¤ë²„ë¦¬ì§€ì™€ í•¨ê»˜ ì‹¤í–‰
pytest --cov=services tests/
```

---

## ì„±ëŠ¥ ìµœì í™”

### 1. ë¹„ë™ê¸° ì²˜ë¦¬

```python
import asyncio
from concurrent.futures import ThreadPoolExecutor

class OptimizedService:
    def __init__(self):
        self.executor = ThreadPoolExecutor(max_workers=4)
    
    async def parallel_processing(self, items: list):
        """ì—¬ëŸ¬ ì‘ì—…ì„ ë³‘ë ¬ë¡œ ì²˜ë¦¬"""
        tasks = [self._process_item(item) for item in items]
        results = await asyncio.gather(*tasks, return_exceptions=True)
        return [r for r in results if not isinstance(r, Exception)]
    
    async def cpu_intensive_task(self, data):
        """CPU ì§‘ì•½ì  ì‘ì—…ì„ ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰"""
        loop = asyncio.get_event_loop()
        result = await loop.run_in_executor(
            self.executor, 
            self._cpu_intensive_work, 
            data
        )
        return result
```

### 2. ë©”ëª¨ë¦¬ ìµœì í™”

```python
from functools import lru_cache
import weakref

class CachedService:
    def __init__(self):
        self._cache = weakref.WeakValueDictionary()
    
    @lru_cache(maxsize=128)
    def expensive_computation(self, input_data: str) -> str:
        """ê²°ê³¼ë¥¼ ìºì‹œí•˜ëŠ” ë¹„ìš©ì´ í° ì—°ì‚°"""
        # ë³µì¡í•œ ê³„ì‚°
        return result
    
    async def get_with_cache(self, key: str):
        """ì•½í•œ ì°¸ì¡°ë¥¼ ì‚¬ìš©í•œ ìºì‹œ"""
        if key in self._cache:
            return self._cache[key]
        
        result = await self._compute_result(key)
        self._cache[key] = result
        return result
```

### 3. ë°ì´í„°ë² ì´ìŠ¤ ìµœì í™”

```python
class OptimizedRepository:
    async def batch_insert(self, items: list[dict]):
        """ë°°ì¹˜ ì‚½ì…ìœ¼ë¡œ ì„±ëŠ¥ í–¥ìƒ"""
        query = """
            INSERT INTO table_name (col1, col2) 
            VALUES ($1, $2)
        """
        
        async with self.db_pool.acquire() as conn:
            await conn.executemany(query, [
                (item['col1'], item['col2']) for item in items
            ])
    
    async def paginated_query(self, offset: int, limit: int):
        """í˜ì´ì§€ë„¤ì´ì…˜ìœ¼ë¡œ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì œí•œ"""
        query = """
            SELECT * FROM large_table 
            ORDER BY id 
            OFFSET $1 LIMIT $2
        """
        
        async with self.db_pool.acquire() as conn:
            rows = await conn.fetch(query, offset, limit)
            return [dict(row) for row in rows]
```

### 4. BM25 ê²€ìƒ‰ ìºì‹œ

- **ëª©ì **: ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ë¹ ë¥¸ ì‹œì‘ì„ ìœ„í•´, BM25 ê²€ìƒ‰ ëª¨ë¸ì„ ë¯¸ë¦¬ ê³„ì‚°í•˜ì—¬ íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
- **íŒŒì¼ ìœ„ì¹˜**: `data/preprocessed/bm25_cache.pkl`
- **ìë™ ìƒì„±**: ì´ ìºì‹œ íŒŒì¼ì´ ì—†ì„ ê²½ìš°, ì„œë²„ê°€ ì²˜ìŒ ì‹œì‘ë  ë•Œ ìë™ìœ¼ë¡œ ìƒì„±ë©ë‹ˆë‹¤. 
  - **ì£¼ì˜**: ìµœì´ˆ ìƒì„± ì‹œì—ëŠ” ì•½ 45,000ê°œì˜ íŒë¡€ë¥¼ ì²˜ë¦¬í•˜ë¯€ë¡œ **ìˆ˜ ë¶„ì˜ ì‹œê°„**ì´ ì†Œìš”ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
- **ìˆ˜ë™ ê°±ì‹ **: ì†ŒìŠ¤ íŒë¡€ ë°ì´í„°(`data/preprocessed/` ë‚´ì˜ JSON íŒŒì¼ë“¤)ê°€ ë³€ê²½ëœ ê²½ìš°, `bm25_cache.pkl` íŒŒì¼ì„ **ìˆ˜ë™ìœ¼ë¡œ ì‚­ì œ**í•´ì•¼ í•©ë‹ˆë‹¤. ì‚­ì œ í›„ ì„œë²„ë¥¼ ì¬ì‹œì‘í•˜ë©´ ìºì‹œê°€ ìë™ìœ¼ë¡œ ë‹¤ì‹œ ìƒì„±ë©ë‹ˆë‹¤.

---

## ğŸ“š ê´€ë ¨ ë¬¸ì„œ

- [API ë¬¸ì„œ](API.md)
- [í…ŒìŠ¤íŠ¸ ê°€ì´ë“œ](TESTING.md)
- [ë°°í¬ ê°€ì´ë“œ](DEPLOYMENT.md)
- [ì•„í‚¤í…ì²˜ ê°€ì´ë“œ](ARCHITECTURE.md)